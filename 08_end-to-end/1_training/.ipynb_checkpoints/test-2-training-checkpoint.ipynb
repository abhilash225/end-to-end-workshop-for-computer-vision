{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "default_bucket = sess.default_bucket() # or use your own custom bucket name\n",
    "account = sess.account_id()\n",
    "base_job_prefix = 'BirdEnd2End'\n",
    "region = sagemaker.Session().boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "from sagemaker.debugger import (ProfilerConfig,\n",
    "                                FrameworkProfile,\n",
    "                                CollectionConfig,\n",
    "                                DebuggerHookConfig,\n",
    "                                DetailedProfilingConfig, \n",
    "                                DataloaderProfilingConfig, \n",
    "                                PythonProfilingConfig,\n",
    "                                Rule,\n",
    "                                PythonProfiler,\n",
    "                                cProfileTimer,\n",
    "                                ProfilerRule,\n",
    "                                rule_configs)\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "\n",
    "TF_FRAMEWORK_VERSION = '2.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location in S3 where the debugger output will be stored is mentioned in the previous step\n",
    "\n",
    "# Set the profile config for both system and framework metrics\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis = 500,\n",
    "    framework_profile_params = FrameworkProfile(\n",
    "        detailed_profiling_config = DetailedProfilingConfig(\n",
    "            start_step = 5, \n",
    "            num_steps = 10\n",
    "        ),\n",
    "        dataloader_profiling_config = DataloaderProfilingConfig(\n",
    "            start_step = 7, \n",
    "            num_steps = 10\n",
    "        ),\n",
    "        python_profiling_config = PythonProfilingConfig(\n",
    "            start_step = 9, \n",
    "            num_steps = 10,\n",
    "            python_profiler = PythonProfiler.CPROFILE, \n",
    "            cprofile_timer = cProfileTimer.TOTAL_TIME\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Set the debugger hook config to save tensors\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    collection_configs = [\n",
    "        CollectionConfig(name = 'weights'),\n",
    "        CollectionConfig(name = 'gradients')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Set the rules to analyze tensors emitted during training\n",
    "# These specific set of rules will inspect the overall training performance and progress of the model\n",
    "rules=[\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "#     Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "#     Rule.sagemaker(rule_configs.overfit()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "checkpoint_s3_uri = f's3://{default_bucket}/{base_job_prefix}/checkpoints/{uuid.uuid4()}'\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/{base_job_prefix}\"\n",
    "\n",
    "instance_type  = 'ml.p3.2xlarge'#'ml.p3.16xlarge'#\n",
    "instance_count = 1\n",
    "\n",
    "gpus_per_host = 1\n",
    "\n",
    "hyperparameters = {'lr':                 0.00012367461028516715, #0.000019,\n",
    "                   'batch_size':         8,\n",
    "                   'epochs':             38, #36, \n",
    "                   'dropout':            0.7459862089753134, #0.76,\n",
    "                   'data_dir':           '/opt/ml/input/data'}\n",
    "    \n",
    "metric_definitions = [{'Name': 'loss',      'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'acc',       'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'val_loss',  'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "                      {'Name': 'val_acc',   'Regex': 'val_accuracy: ([0-9\\\\.]+)'}]\n",
    "\n",
    "distribution = {'parameter_server': {'enabled': False}}\n",
    "\n",
    "estimator = TensorFlow(entry_point='train.py',\n",
    "                       source_dir='pipeline/code',\n",
    "                       instance_type=instance_type,\n",
    "                       instance_count=instance_count,\n",
    "                       distribution=distribution,\n",
    "                       output_path=model_path,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       metric_definitions=metric_definitions,\n",
    "                       role=role,\n",
    "                       framework_version=TF_FRAMEWORK_VERSION, \n",
    "                       py_version='py3',\n",
    "                       base_job_name=f\"{base_job_prefix}-debugger\",\n",
    "                       profiler_config=profiler_config,\n",
    "                       debugger_hook_config=debugger_hook_config,\n",
    "                       rules=rules,\n",
    "                       input_mode='Pipe',\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training container related parameters\n",
    "\n",
    "output_s3_uri = f's3://{default_bucket}/{base_job_prefix}/scriptprocessor/output/preprocess'\n",
    "\n",
    "s3_train = output_s3_uri +'/train'\n",
    "s3_valid = output_s3_uri +'/valid'\n",
    "\n",
    "DISTRIBUTION_MODE = 'FullyReplicated'\n",
    "\n",
    "# output_s3_uri is the output from previous process.\n",
    "\n",
    "train_in = TrainingInput(s3_data=s3_train, distribution=DISTRIBUTION_MODE)\n",
    "val_in   = TrainingInput(s3_data=s3_valid, distribution=DISTRIBUTION_MODE)\n",
    "\n",
    "inputs = {'train':train_in, 'valid': val_in}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "\n",
    "print(f\"model artifacts file is uploaded here: {model_path}/{training_job_name}/output ========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator2 = TensorFlow(entry_point='train.py',\n",
    "                       source_dir='pipeline/code',\n",
    "                       instance_type=instance_type,\n",
    "                       instance_count=instance_count,\n",
    "                       distribution=distribution,\n",
    "                       output_path=model_path,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       metric_definitions=metric_definitions,\n",
    "                       role=role,\n",
    "                       framework_version=TF_FRAMEWORK_VERSION, \n",
    "                       py_version='py3',\n",
    "                       base_job_name=base_job_prefix,\n",
    "                       input_mode='Pipe',\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'epochs': IntegerParameter(30, 40),\n",
    "    'dropout': ContinuousParameter(0.5, 0.8),\n",
    "    'lr': ContinuousParameter(0.00001, 0.001)}\n",
    "\n",
    "objective_metric_name = 'val_acc'\n",
    "objective_type = 'Maximize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator2,\n",
    "                        objective_metric_name,\n",
    "                        hyperparameter_ranges,\n",
    "                        metric_definitions,\n",
    "                        max_jobs=2,\n",
    "                        max_parallel_jobs=2,\n",
    "                        objective_type=objective_type,\n",
    "                        base_tuning_job_name=f\"{base_job_prefix}-tuning\")\n",
    "\n",
    "tuner.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
